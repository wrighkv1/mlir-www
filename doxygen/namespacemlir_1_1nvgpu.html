<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: mlir::nvgpu Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">16.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacemlir.html">mlir</a></li><li class="navelem"><a class="el" href="namespacemlir_1_1nvgpu.html">nvgpu</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">mlir::nvgpu Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collects information about a warp-level matrix operand represented by a VectorType.  <a href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies information about the registers which compose a matrix fragment according to the PTX documentation.  <a href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Encapsulates the parameters needed to lower a <code>nvgpu.ldmatrix</code> operation to <code>nvvm.ldmatrix</code>.  <a href="structmlir_1_1nvgpu_1_1LdMatrixParams.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1PrepareContractToGPUMMASync.html">PrepareContractToGPUMMASync</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Transform <code>vector.contract</code> into (m,k)x(n,k)x(m,n) form so that it can be converted to <code>nvgpu.mma.sync</code>.  <a href="structmlir_1_1nvgpu_1_1PrepareContractToGPUMMASync.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a2cd481d969335c7faee4833fd989f8ed"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">MmaSyncF32Lowering</a> { <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">TF32</a> = 0
, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8edab0496676569bf2251989f4011ec01965">TF32x3</a> = 1
, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda777358f6554241fd6bb9110bf267b3ac">Unkown</a> = 2
 }</td></tr>
<tr class="memdesc:a2cd481d969335c7faee4833fd989f8ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rewrites patterns.  <a href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">More...</a><br /></td></tr>
<tr class="separator:a2cd481d969335c7faee4833fd989f8ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4c82fd5e3500e2d345d723829e09efe"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">MatMulOperandRole</a> : int32_t { <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a> = 0
, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571">B</a>
, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>
 }</td></tr>
<tr class="memdesc:ae4c82fd5e3500e2d345d723829e09efe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Represents the role of an operand in an MMA instruction: <code>result := matmul(A, B) + C</code>  <a href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">More...</a><br /></td></tr>
<tr class="separator:ae4c82fd5e3500e2d345d723829e09efe"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a6783845748d4e0a1c685d19edbf53314"><td class="memItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classmlir_1_1Pass.html">Pass</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a6783845748d4e0a1c685d19edbf53314">createOptimizeSharedMemoryPass</a> ()</td></tr>
<tr class="memdesc:a6783845748d4e0a1c685d19edbf53314"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a pass to optimize shared memory reads and writes.  <a href="namespacemlir_1_1nvgpu.html#a6783845748d4e0a1c685d19edbf53314">More...</a><br /></td></tr>
<tr class="separator:a6783845748d4e0a1c685d19edbf53314"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a010447568ef41c55d4132343c45bae8f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structmlir_1_1LogicalResult.html">mlir::LogicalResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a010447568ef41c55d4132343c45bae8f">optimizeSharedMemoryReadsAndWrites</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *parentOp, <a class="el" href="classmlir_1_1Value.html">Value</a> memrefValue)</td></tr>
<tr class="memdesc:a010447568ef41c55d4132343c45bae8f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Passes.  <a href="namespacemlir_1_1nvgpu.html#a010447568ef41c55d4132343c45bae8f">More...</a><br /></td></tr>
<tr class="separator:a010447568ef41c55d4132343c45bae8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d4c259957fcb36c77d32413688cd447"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a7d4c259957fcb36c77d32413688cd447">populateMmaSyncF32ToTF32Patterns</a> (<a class="el" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;patterns, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">nvgpu::MmaSyncF32Lowering</a> precision=<a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">nvgpu::MmaSyncF32Lowering::TF32</a>)</td></tr>
<tr class="memdesc:a7d4c259957fcb36c77d32413688cd447"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collect patterns to convert mma.sync on f32 input and rewrite to use tensor cores with user provided level of accuracy: (a) tf32 (1 mma.sync per warp-level matrix-multiply-accumulate) (b) tf32x3 (3 mma.sync per warp-level matrix-multiply-accumulate) Typically, tf32 tensor core acceleration comes at a cost of accuracy from missing precision bits.  <a href="namespacemlir_1_1nvgpu.html#a7d4c259957fcb36c77d32413688cd447">More...</a><br /></td></tr>
<tr class="separator:a7d4c259957fcb36c77d32413688cd447"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; vector::ContractionOp &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a5e5e9578e2fea736fe8b33cdbb846a75">getUserContract</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the first user of the <code>op</code> that is vector.contract.  <a href="namespacemlir_1_1nvgpu.html#a5e5e9578e2fea736fe8b33cdbb846a75">More...</a><br /></td></tr>
<tr class="separator:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a833cda849d4c16ca9e572b561a3d7c8c"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a833cda849d4c16ca9e572b561a3d7c8c">getWarpMatrixInfo</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:a833cda849d4c16ca9e572b561a3d7c8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">If <code>op</code> is a <code>vector.transfer_write</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> for the vector operand.  <a href="namespacemlir_1_1nvgpu.html#a833cda849d4c16ca9e572b561a3d7c8c">More...</a><br /></td></tr>
<tr class="separator:a833cda849d4c16ca9e572b561a3d7c8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c7d221188b7c25a9615d098a69a8961"><td class="memItemLeft" align="right" valign="top">int64_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a5c7d221188b7c25a9615d098a69a8961">inferTileWidthInBits</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type)</td></tr>
<tr class="memdesc:a5c7d221188b7c25a9615d098a69a8961"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the number of bits in a single tile row.  <a href="namespacemlir_1_1nvgpu.html#a5c7d221188b7c25a9615d098a69a8961">More...</a><br /></td></tr>
<tr class="separator:a5c7d221188b7c25a9615d098a69a8961"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc4ec5365767add53c11a004b407c2c8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#afc4ec5365767add53c11a004b407c2c8">getMmaSyncRegisterType</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type)</td></tr>
<tr class="memdesc:afc4ec5365767add53c11a004b407c2c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html" title="Specifies information about the registers which compose a matrix fragment according to the PTX docume...">FragmentElementInfo</a> struct describing the register types for the given matrix fragment type.  <a href="namespacemlir_1_1nvgpu.html#afc4ec5365767add53c11a004b407c2c8">More...</a><br /></td></tr>
<tr class="separator:afc4ec5365767add53c11a004b407c2c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ff41977f6fa45aa286d58c0c539f7eb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a0ff41977f6fa45aa286d58c0c539f7eb">getLaneIdAndValueIdToOperandCoord</a> (<a class="el" href="classmlir_1_1Location.html">Location</a> loc, <a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;fragmentType)</td></tr>
<tr class="memdesc:a0ff41977f6fa45aa286d58c0c539f7eb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a two dimensions representing (laneId, logicalValueId) and returns two results representing offsets within a matrix operand.  <a href="namespacemlir_1_1nvgpu.html#a0ff41977f6fa45aa286d58c0c539f7eb">More...</a><br /></td></tr>
<tr class="separator:a0ff41977f6fa45aa286d58c0c539f7eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedec27c25c18f9d99a07975a272e45b7"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#aedec27c25c18f9d99a07975a272e45b7">getLdMatrixParams</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type, bool transpose)</td></tr>
<tr class="memdesc:aedec27c25c18f9d99a07975a272e45b7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given <code>type</code> that contains info for a warp-matrix operand and whether or not the load is a transposed load, return the <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html" title="Encapsulates the parameters needed to lower a nvgpu.ldmatrix operation to nvvm.ldmatrix.">LdMatrixParams</a>.  <a href="namespacemlir_1_1nvgpu.html#aedec27c25c18f9d99a07975a272e45b7">More...</a><br /></td></tr>
<tr class="separator:aedec27c25c18f9d99a07975a272e45b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f9143e901e581d0a1cc65cb0b710707"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a1f9143e901e581d0a1cc65cb0b710707">getLaneIdToLdMatrixMatrixCoord</a> (<a class="el" href="classmlir_1_1Location.html">Location</a> loc, <a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, const <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &amp;params)</td></tr>
<tr class="memdesc:a1f9143e901e581d0a1cc65cb0b710707"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a single dimension representing the laneId to two results representing offsets within the matrix operand that should be the pointer locations a thread should pass to the ldmatrix instruction.  <a href="namespacemlir_1_1nvgpu.html#a1f9143e901e581d0a1cc65cb0b710707">More...</a><br /></td></tr>
<tr class="separator:a1f9143e901e581d0a1cc65cb0b710707"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="ae4c82fd5e3500e2d345d723829e09efe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4c82fd5e3500e2d345d723829e09efe">&#9670;&nbsp;</a></span>MatMulOperandRole</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">mlir::nvgpu::MatMulOperandRole</a> : int32_t</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Represents the role of an operand in an MMA instruction: <code>result := matmul(A, B) + C</code> </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29"></a>A&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571"></a>B&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257"></a>C&#160;</td><td class="fielddoc"></td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8h_source.html#l00026">26</a> of file <a class="el" href="MMAUtils_8h_source.html">MMAUtils.h</a>.</p>

</div>
</div>
<a id="a2cd481d969335c7faee4833fd989f8ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cd481d969335c7faee4833fd989f8ed">&#9670;&nbsp;</a></span>MmaSyncF32Lowering</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">mlir::nvgpu::MmaSyncF32Lowering</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Rewrites patterns. </p>
<p>Enum to control the lowering of <code>nvgpu.mmasync</code>. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6"></a>TF32&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8edab0496676569bf2251989f4011ec01965"></a>TF32x3&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8eda777358f6554241fd6bb9110bf267b3ac"></a>Unkown&#160;</td><td class="fielddoc"></td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="mlir_2Dialect_2NVGPU_2Transforms_2Transforms_8h_source.html#l00056">56</a> of file <a class="el" href="mlir_2Dialect_2NVGPU_2Transforms_2Transforms_8h_source.html">Transforms.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="a6783845748d4e0a1c685d19edbf53314"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6783845748d4e0a1c685d19edbf53314">&#9670;&nbsp;</a></span>createOptimizeSharedMemoryPass()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt; <a class="el" href="classmlir_1_1Pass.html">Pass</a> &gt; mlir::nvgpu::createOptimizeSharedMemoryPass </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a pass to optimize shared memory reads and writes. </p>

<p class="definition">Definition at line <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00278">278</a> of file <a class="el" href="OptimizeSharedMemory_8cpp_source.html">OptimizeSharedMemory.cpp</a>.</p>

</div>
</div>
<a id="a0ff41977f6fa45aa286d58c0c539f7eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ff41977f6fa45aa286d58c0c539f7eb">&#9670;&nbsp;</a></span>getLaneIdAndValueIdToOperandCoord()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt; mlir::nvgpu::getLaneIdAndValueIdToOperandCoord </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Location.html">Location</a>&#160;</td>
          <td class="paramname"><em>loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;&#160;</td>
          <td class="paramname"><em>builder</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>fragmentType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a two dimensions representing (laneId, logicalValueId) and returns two results representing offsets within a matrix operand. </p>
<p>The offsets point to the values the thread is responsible for (AKA the matrix fragment values) during a warp-collective matrix operation. For a visual reference of this LaneId -&gt; (row, col) mapping, please see NVIDIA's PTX documentation: <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-for-mma">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-for-mma</a> </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00173">173</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="mlir_2IR_2AffineExpr_8h_source.html#l00336">mlir::bindDims()</a>, <a class="el" href="LogicalResult_8h_source.html#l00072">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00764">mlir::AffineExpr::floorDiv()</a>, <a class="el" href="MLIRContext_8cpp_source.html#l01043">mlir::AffineMap::get()</a>, <a class="el" href="Builders_8h_source.html#l00054">mlir::Builder::getContext()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00093">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00100">getMmaSyncRegisterType()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00154">getRegisterIndexToTileOffsetMap()</a>, <a class="el" href="IR_2AffineMap_8cpp_source.html#l00323">mlir::AffineMap::getResult()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00087">inferTileWidthInBits()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00023">isAccumulatorOrResult()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00020">kThreadsPerRow</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00669">convertTransferWriteToStores()</a>, and <a class="el" href="VectorToGPU_8cpp_source.html#l00550">createNonLdMatrixLoads()</a>.</p>

</div>
</div>
<a id="a1f9143e901e581d0a1cc65cb0b710707"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f9143e901e581d0a1cc65cb0b710707">&#9670;&nbsp;</a></span>getLaneIdToLdMatrixMatrixCoord()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt; mlir::nvgpu::getLaneIdToLdMatrixMatrixCoord </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Location.html">Location</a>&#160;</td>
          <td class="paramname"><em>loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;&#160;</td>
          <td class="paramname"><em>builder</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a single dimension representing the laneId to two results representing offsets within the matrix operand that should be the pointer locations a thread should pass to the ldmatrix instruction. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00238">238</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="MMAUtils_8h_source.html#l00081">mlir::nvgpu::LdMatrixParams::contiguousDimType</a>, <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00764">mlir::AffineExpr::floorDiv()</a>, <a class="el" href="MMAUtils_8h_source.html#l00078">mlir::nvgpu::LdMatrixParams::fragmentType</a>, <a class="el" href="MLIRContext_8cpp_source.html#l01043">mlir::AffineMap::get()</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00488">mlir::getAffineDimExpr()</a>, <a class="el" href="Builders_8h_source.html#l00054">mlir::Builder::getContext()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00021">kNumRowsPerTile</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00506">creatLdMatrixCompatibleLoads()</a>.</p>

</div>
</div>
<a id="aedec27c25c18f9d99a07975a272e45b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aedec27c25c18f9d99a07975a272e45b7">&#9670;&nbsp;</a></span>getLdMatrixParams()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">nvgpu::LdMatrixParams</a> &gt; mlir::nvgpu::getLdMatrixParams </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given <code>type</code> that contains info for a warp-matrix operand and whether or not the load is a transposed load, return the <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html" title="Encapsulates the parameters needed to lower a nvgpu.ldmatrix operation to nvvm.ldmatrix.">LdMatrixParams</a>. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00209">209</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>, <a class="el" href="MMAUtils_8h_source.html#l00081">mlir::nvgpu::LdMatrixParams::contiguousDimType</a>, <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, <a class="el" href="MMAUtils_8h_source.html#l00078">mlir::nvgpu::LdMatrixParams::fragmentType</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00093">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00021">kNumRowsPerTile</a>, <a class="el" href="MMAUtils_8h_source.html#l00080">mlir::nvgpu::LdMatrixParams::numTiles</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, <a class="el" href="MMAUtils_8h_source.html#l00082">mlir::nvgpu::LdMatrixParams::targetLayout</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00506">creatLdMatrixCompatibleLoads()</a>.</p>

</div>
</div>
<a id="afc4ec5365767add53c11a004b407c2c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc4ec5365767add53c11a004b407c2c8">&#9670;&nbsp;</a></span>getMmaSyncRegisterType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a> &gt; mlir::nvgpu::getMmaSyncRegisterType </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns a <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html" title="Specifies information about the registers which compose a matrix fragment according to the PTX docume...">FragmentElementInfo</a> struct describing the register types for the given matrix fragment type. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00100">100</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, <a class="el" href="LLVMTypes_8cpp_source.html#l00934">mlir::LLVM::getFixedVectorType()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00029">inferNumRegistersPerMatrixFragment()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00023">isAccumulatorOrResult()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00024">mlir::Type::isF16()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00025">mlir::Type::isF32()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00026">mlir::Type::isF64()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00033">mlir::Type::isInteger()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00481">convertConstantOpMmaSync()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00713">convertExtractStridedSlice()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00669">convertTransferWriteToStores()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00550">createNonLdMatrixLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00506">creatLdMatrixCompatibleLoads()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00173">getLaneIdAndValueIdToOperandCoord()</a>.</p>

</div>
</div>
<a id="a5e5e9578e2fea736fe8b33cdbb846a75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e5e9578e2fea736fe8b33cdbb846a75">&#9670;&nbsp;</a></span>getUserContract()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; vector::ContractionOp &gt; mlir::nvgpu::getUserContract </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the first user of the <code>op</code> that is vector.contract. </p>
<p>If no vector.contract user exists, return failure. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00050">50</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, and <a class="el" href="IR_2Operation_8h_source.html#l00650">mlir::Operation::getUsers()</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00198">extractStridedSliceSupportsMMAMatrixType()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00058">getWarpMatrixInfo()</a>.</p>

</div>
</div>
<a id="a833cda849d4c16ca9e572b561a3d7c8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a833cda849d4c16ca9e572b561a3d7c8c">&#9670;&nbsp;</a></span>getWarpMatrixInfo()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1FailureOr.html">FailureOr</a>&lt; <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &gt; mlir::nvgpu::getWarpMatrixInfo </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>If <code>op</code> is a <code>vector.transfer_write</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> for the vector operand. </p>
<p>If op is a <code>vector.transfer_read</code>, <code>vector.contraction</code>, or <code>arith.constant</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> corresponding to the result. Otherwise, return failure. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00058">58</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571">B</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>, <a class="el" href="IR_2Types_8h_source.html#l00280">mlir::Type::cast()</a>, <a class="el" href="IR_2Operation_8cpp_source.html#l00225">mlir::Operation::emitError()</a>, <a class="el" href="LogicalResult_8h_source.html#l00072">mlir::failed()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00324">mlir::Operation::getResult()</a>, <a class="el" href="Value_8h_source.html#l00114">mlir::Value::getType()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00050">getUserContract()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00481">convertConstantOpMmaSync()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00713">convertExtractStridedSlice()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00638">convertTransferReadToLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00669">convertTransferWriteToStores()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00550">createNonLdMatrixLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00506">creatLdMatrixCompatibleLoads()</a>, and <a class="el" href="VectorToGPU_8cpp_source.html#l00198">extractStridedSliceSupportsMMAMatrixType()</a>.</p>

</div>
</div>
<a id="a5c7d221188b7c25a9615d098a69a8961"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c7d221188b7c25a9615d098a69a8961">&#9670;&nbsp;</a></span>inferTileWidthInBits()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int64_t mlir::nvgpu::inferTileWidthInBits </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the number of bits in a single tile row. </p>
<p>It is either 128, 256, or 512 bits depending on the data type and` whether the operand is an accumulator/result operand </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00087">87</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="IR_2Types_8cpp_source.html#l00093">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00023">isAccumulatorOrResult()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00638">convertTransferReadToLoads()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00173">getLaneIdAndValueIdToOperandCoord()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00029">inferNumRegistersPerMatrixFragment()</a>.</p>

</div>
</div>
<a id="a010447568ef41c55d4132343c45bae8f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a010447568ef41c55d4132343c45bae8f">&#9670;&nbsp;</a></span>optimizeSharedMemoryReadsAndWrites()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structmlir_1_1LogicalResult.html">mlir::LogicalResult</a> mlir::nvgpu::optimizeSharedMemoryReadsAndWrites </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>parentOp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td>
          <td class="paramname"><em>memrefValue</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Passes. </p>
<p>Optimizes vectorized accesses to a shared memory buffer specified by memrefValue. This transformation assumes the following: 1) All relevant accesses to <code>memrefValue</code> are contained with <code>parentOp</code>. 2) The function will fail precondition checks if any subviews are taken of <code>memrefValue</code>. All reads/writes to <code>memrefValue</code> should occur through <code>memrefValue</code> directly.</p>
<p>Shared memory bank conflicts occur when multiple threads attempt to read or write locations assigned to the same shared memory bank. For <code>2^N</code> byte vectorized accesses, we need to be concerned with conflicts among threads identified as <code>(tid) -&gt; tid.floordiv(2^{7-N})</code>. As such, this transformation changes any indexed memory access (vector.load, memref.load, nvgpu.ldmatrix, etc) such that the final dimension's index value is permuted such that <code>newColIndex = oldColIndex % vectorSize + perm[rowIndex](oldColIndex/vectorSize, rowIndex)</code> where <code>rowIndex</code> is the index for the second-to last dimension and <code>perm[rowIndex]</code> is a permutation function that depends on the row Index. The permutation function is chosen to ensure that sequential distributed+vectorized reads/writes down a single dimension of the memref have minimal conflicts. </p>

<p class="definition">Definition at line <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00181">181</a> of file <a class="el" href="OptimizeSharedMemory_8cpp_source.html">OptimizeSharedMemory.cpp</a>.</p>

<p class="reference">References <a class="el" href="IR_2Types_8h_source.html#l00270">mlir::Type::dyn_cast()</a>, <a class="el" href="LogicalResult_8h_source.html#l00072">mlir::failed()</a>, <a class="el" href="LogicalResult_8h_source.html#l00062">mlir::failure()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00147">mlir::Operation::getContext()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00110">getIndices()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00154">mlir::Operation::getLoc()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00145">getShmReadAndWriteOps()</a>, <a class="el" href="Value_8h_source.html#l00114">mlir::Value::getType()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00040">kDefaultVectorSizeBits</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00037">kSharedMemoryLineSizeBytes</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00126">setIndices()</a>, <a class="el" href="Builders_8h_source.html#l00350">mlir::OpBuilder::setInsertionPoint()</a>, <a class="el" href="LogicalResult_8h_source.html#l00056">mlir::success()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00102">transformIndices()</a>, and <a class="el" href="IR_2Operation_8h_source.html#l00574">mlir::Operation::walk()</a>.</p>

</div>
</div>
<a id="a7d4c259957fcb36c77d32413688cd447"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d4c259957fcb36c77d32413688cd447">&#9670;&nbsp;</a></span>populateMmaSyncF32ToTF32Patterns()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void mlir::nvgpu::populateMmaSyncF32ToTF32Patterns </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;&#160;</td>
          <td class="paramname"><em>patterns</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">nvgpu::MmaSyncF32Lowering</a>&#160;</td>
          <td class="paramname"><em>precision</em> = <code><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">nvgpu::MmaSyncF32Lowering::TF32</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Collect patterns to convert mma.sync on f32 input and rewrite to use tensor cores with user provided level of accuracy: (a) tf32 (1 mma.sync per warp-level matrix-multiply-accumulate) (b) tf32x3 (3 mma.sync per warp-level matrix-multiply-accumulate) Typically, tf32 tensor core acceleration comes at a cost of accuracy from missing precision bits. </p>
<p>While f32 has 23 precision bits, tf32 has only 10 precision bits. tf32x3 aims to recover the precision bits by spliting each operand into two tf32 values and issue three mma.sync tensor core operations. </p>

<p class="definition">Definition at line <a class="el" href="MmaSyncTF32Transform_8cpp_source.html#l00069">69</a> of file <a class="el" href="MmaSyncTF32Transform_8cpp_source.html">MmaSyncTF32Transform.cpp</a>.</p>

<p class="reference">References <a class="el" href="PatternMatch_8h_source.html#l01587">mlir::RewritePatternSet::add()</a>, and <a class="el" href="PatternMatch_8h_source.html#l01563">mlir::RewritePatternSet::getContext()</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Nov 17 2022 20:37:50 for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
